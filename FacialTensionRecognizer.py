# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-Gdc1S3MlZW5lQoiaJZO5i_54i8svzNI
"""

# Install and import libraries
!pip install deepface
import cv2
import numpy as np
import pandas as pd
import glob
import os
from deepface import DeepFace
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score
from google.colab import drive

# Mount Google Drive
drive.mount('/content/drive')

# Paths to your video folders
video_folders = [
    '/content/drive/MyDrive/ECE460JData/TestVideo/Deceptive/Deceptive',
    '/content/drive/MyDrive/ECE460JData/TestVideo/Truthful/Truthful'
]

# Haar cascades for face and eye detection
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')

# Gaze detection function
def analyze_gaze(video_path, max_frames=50):
    cap = cv2.VideoCapture(video_path)
    frame_count = 0
    up_left_count = 0
    neutral_count = 0
    success, frame = cap.read()

    while success and frame_count < max_frames:
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        faces = face_cascade.detectMultiScale(gray, 1.3, 5)

        for (x, y, w, h) in faces:
            roi_gray = gray[y:y + h, x:x + w]
            eyes = eye_cascade.detectMultiScale(roi_gray)
            for (ex, ey, ew, eh) in eyes[:1]:  # only first detected eye
                eye = roi_gray[ey:ey + eh, ex:ex + ew]
                _, threshold = cv2.threshold(eye, 50, 255, cv2.THRESH_BINARY_INV)
                contours, _ = cv2.findContours(threshold, cv2.RETR_TREE, cv2.CHAIN_APPROX_SIMPLE)
                if contours:
                    cnt = max(contours, key=cv2.contourArea)
                    (cx, cy), radius = cv2.minEnclosingCircle(cnt)
                    if 5 < cv2.contourArea(cnt) < 500:
                        if cx < ew / 2 and cy < eh / 2:
                            up_left_count += 1
                        else:
                            neutral_count += 1

        success, frame = cap.read()
        frame_count += 1

    cap.release()
    total = up_left_count + neutral_count
    up_left_percent = (up_left_count / total) * 100 if total else 0
    return up_left_percent

# Main Loop over videos
results = []

for folder in video_folders:
    video_paths = glob.glob(os.path.join(folder, '*.mp4'))

    for video_path in video_paths:
        video_name = os.path.basename(video_path).lower()
        label = 'deceptive' if 'lie' in video_name else 'honest'

        # DeepFace tension detection
        cap = cv2.VideoCapture(video_path)
        frame_count = 0
        tension_count = 0
        neutral_count = 0
        success, frame = cap.read()

        while success and frame_count < 20:  # only first 20 frames
            try:
                result = DeepFace.analyze(frame, actions=['emotion'], enforce_detection=False)
                emotion = result[0]['dominant_emotion']
                if emotion in ['angry', 'fear', 'disgust', 'sad']:
                    tension_count += 1
                else:
                    neutral_count += 1
            except:
                pass  # Skip bad frames

            success, frame = cap.read()
            frame_count += 1

        cap.release()

        total_frames = tension_count + neutral_count
        tension_percent = (tension_count / total_frames) * 100 if total_frames > 0 else 0

        # Gaze detection
        up_left_percent = analyze_gaze(video_path)

        results.append({
            'video': os.path.basename(video_path),
            'tension_percent': tension_percent,
            'up_left_percent': up_left_percent,
            'label': label
        })

        print(f"{os.path.basename(video_path)} - Tension: {tension_percent:.2f}% | Gaze Up-Left: {up_left_percent:.2f}% | Label: {label}")

# Create DataFrame
df = pd.DataFrame(results)
df['label_num'] = df['label'].map({'honest': 0, 'deceptive': 1})

# Features: tension + gaze
X = df[['tension_percent', 'up_left_percent']]
y = df['label_num']

# Train/Test split
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Logistic Regression model
model = LogisticRegression()
model.fit(X_train, y_train)

# Evaluate
y_pred = model.predict(X_test)
print("\nModel Performance:")
print("Accuracy:", accuracy_score(y_test, y_pred))
print(classification_report(y_test, y_pred))

# Final Predictions
df['predicted'] = model.predict(X)
print("\nFinal Predictions:")
print(df[['video', 'tension_percent', 'up_left_percent', 'label', 'predicted']])